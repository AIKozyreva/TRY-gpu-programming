Репозиторий с проектом: https://github.com/dean1t/gpu-programming/tree/master/02

Реализован вариант задания с денойзингом

Детали проекта
    * Задание выполнено на CUDA (GPU часть)
    * Для чтения/записи изображений используется stb_image
        header-only библиотека https://github.com/nothings/stb
    * Сборка с помощью CMake:
        mkdir build
        cd build
        cmake -DCMAKE_BUILD_TYPE=Release ..
        make

    * На Windows (чтобы собрался Release):
        mkdir build
        cd build
        cmake -DCMAKE_BUILD_TYPE=Release ..
        cmake --build . --config Release
    
Запуск приложения
    * На вход подается путь к изображению `path_to_image.png`
    * На выходе результат записывается в `path_to_image_denoised.png`
    * Для корректных замеров времени используется ключ `-b`, 
        с помощью которого модель прогоняется X раз (по умолчанию 100)
    * Help: `-h`
    
        ./denoiser path_to_image [-b [X]]
    
Спецификация ПК
    * i5-8265U @ 1.60GHz, 4 Cores 8 Threads 
    * 8GB RAM
    * NVIDIA GTX 1050-Ti (Mobile Max-Q) 2GB VRAM
    * Сборка и работоспособность тестировались на Windows 11

Описание алгоритма и оптимизаций:
    * В базовой реализации свертки для вычисления каждой feature-map выходного тензора
    запускается отдельное ядро. Ядро использует двумерную сетку, внутри зашито 
    суммирование по всем каналам входного тензора.
        Реализация модели -- метод `Model::forward`
        Реализация свертки -- ядро `conv2d`

    * Объединение слоев свертки+активации достигается с помощью доп. параметра, отвечающего за то,
    какую функцию нужно применить на выходе: LU (т.е. ничего), ReLU или Sigmoid. Сам код вычисления 
    свертки не изменен.
        Реализация модели -- метод `Model::forward_merge_layers`
        Реализация свертки -- ядро `conv2d`

    * Кэширование реализовано через local shared memory. Эта память распределяется между всеми
    нитями в блоке. Оптимизация достигается засчет сокращения количества обращений в глобальную 
    память. Для каждого блока выделяется общая память, в которую гарантированно поместится 
    трехмерная обсчитываемая часть входного трехмерного тензора.
        Реализация модели -- метод `Model::forward_full_optim`
        Реализация свертки -- ядро `conv2d_optim`

    * Транспонированная свертка не требует оптимизации через кэширование изображения 
    (по крайней мере в моей реализации). Каждый пиксель входного изображения используется один раз, поэтому
    его нет смысла кэшировать. Но к ней применима оптимизация через объединение слоев.
        Реализация модели -- метод `Model::forward_transpose`
        Реализация свертки -- ядро `conv2d_transpose`

Замеры времени на 100 запусках на изображении из MNIST размером 28x28 пикселей
    1. Базовая версия (без оптимизаций):
        Elapsed time on one step (no optimization):     2162    [microseconds]
    2. Перенос функций активации внутрь вычисления сверток:
        Elapsed time on one step (merge activations):   2085    [microseconds]
    3. Добавление local shared memory для кэширования данных изображения:
        Elapsed time on one step (activ + shared mem):  2866    [microseconds]

Замеры времени на 100 запусках на изображении из MNIST размером 256x256 пикселей
    1. Базовая версия (без оптимизаций):
        Elapsed time on one step (no optimization):     12938   [microseconds]
    2. Перенос функций активации внутрь вычисления сверток:
        Elapsed time on one step (merge activations):   10413   [microseconds]
    3. Добавление local shared memory для кэширования данных изображения:
        Elapsed time on one step (activ + shared mem):  13159   [microseconds]

Оптимизация с помощью кэширования данных изображения не дает ускорения.
Но результаты скорости работы сильно похожи, и от запуска к запуску только второй 
вариант стабильно лучше.

