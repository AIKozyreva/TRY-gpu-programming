Репозиторий с проектом: https://github.com/dean1t/gpu-programming/tree/master/02

Реализован вариант задания с денойзингом

Детали проекта
    * Задание выполнено на CUDA (GPU часть)
    * Для чтения/записи изображений используется stb_image
        header-only библиотека https://github.com/nothings/stb
    * Сборка с помощью CMake:
        mkdir build
        cd build
        cmake -DCMAKE_BUILD_TYPE=Release ..
        make

    * На Windows (чтобы собрался Release):
        mkdir build
        cd build
        cmake -DCMAKE_BUILD_TYPE=Release ..
        cmake --build . --config Release
    
Запуск приложения
    * На вход подается путь к изображению `path_to_image.png`
    * На выходе результат записывается в `path_to_image_denoised.png`
    * Для корректных замеров времени используется ключ `-b`, 
        с помощью которого модель прогоняется X раз (по умолчанию 100)
    * Help: `-h`
    
        ./denoiser path_to_image [-b [X]]
    
Спецификация ПК
    * i5-8265U @ 1.60GHz, 4 Cores 8 Threads 
    * 8GB RAM
    * NVIDIA GTX 1050-Ti (Mobile Max-Q) 2GB VRAM
    * Сборка и работоспособность тестировались на Windows 11

Описание алгоритма и оптимизаций:
    * В базовой реализации свертки для вычисления каждой feature-map выходного тензора
    запускается отдельное ядро. Ядро использует двумерную сетку, внутри зашито 
    суммирование по всем каналам входного тензора.
        Реализация модели -- метод `Model::forward`
        Реализация свертки -- ядро `conv2d`

    * Объединение слоев свертки+активации достигается с помощью доп. параметра, отвечающего за то,
    какую функцию нужно применить на выходе: LU (т.е. ничего), ReLU или Sigmoid. Сам код вычисления 
    свертки не изменен.
        Реализация модели -- метод `Model::forward_merge_layers`
        Реализация свертки -- ядро `conv2d`

    * Кэширование реализовано через local shared memory. Эта память распределяется между всеми
    нитями в блоке. Оптимизация достигается засчет сокращения количества обращений в глобальную 
    память. Для каждого блока выделяется общая память, в которую гарантированно поместится 
    трехмерная обсчитываемая часть входного трехмерного тензора.
        Реализация модели -- метод `Model::forward_full_optim`
        Реализация свертки -- ядро `conv2d_img_sharedmem`

    * Вторая реализация через локальную общую память имеет ту же логику, но в ней перенесен внешний цикл
    по каналам на самый вложенный уровень. Мотивация и результаты ниже.
        Реализация модели -- метод `Model::forward_full_optim`
        Реализация свертки -- ядро `conv2d_img_sharedmem2`

    * Транспонированная свертка не требует оптимизации через кэширование изображения 
    (по крайней мере в моей реализации). Каждый пиксель входного изображения используется один раз, поэтому
    его нет смысла кэшировать. Но к ней применима оптимизация через объединение слоев.
        Реализация модели -- метод `Model::forward_transpose`
        Реализация свертки -- ядро `conv2d_transpose`

Замеры времени на 100 запусках на изображении из MNIST размером 28x28 пикселей
    1. Базовая версия (без оптимизаций):
        Elapsed time on one step (no optimization):     2162    [microseconds]
    2. Перенос функций активации внутрь вычисления сверток:
        Elapsed time on one step (merge activations):   2085    [microseconds]
    3. Добавление local shared memory для кэширования данных изображения:
        Elapsed time on one step (activ + shared mem):  2866    [microseconds]
    4. Изменение порядка вложенности циклов в 3 стратегии:
        Elapsed time on one step (activ + shared mem2):  2077    [microseconds]

Замеры времени на 100 запусках на изображении из MNIST размером 256x256 пикселей
    1. Базовая версия (без оптимизаций):
        Elapsed time on one step (no optimization):     12938   [microseconds]
    2. Перенос функций активации внутрь вычисления сверток:
        Elapsed time on one step (merge activations):   10413   [microseconds]
    3. Добавление local shared memory для кэширования данных изображения:
        Elapsed time on one step (activ + shared mem):  17159   [microseconds]
    4. Изменение порядка вложенности циклов в 3 стратегии:
        Elapsed time on one step (activ + shared mem2): 15697   [microseconds]

    Оптимизация с помощью кэширования данных изображения не дает ускорения, а наоборот замедляет.
    Это происходит потому что условий для проверки выходов за границы становится слишком много 
    на каждый отдельный элемент. Если попробовать изменить порядок вложенности циклов, 
    и цикл по каналам сделать самым вложенным, то это дает небольшое преимущество, но все равно 
    замедляет программу. Потому что теперь начинает страдать обычное кэширование данных: чтения идут
    с очень большими интервалами в h*w пикселей. В случае небольшого изображения (28х28)
    это действительно сильно ускоряет третью стратегию, она становится наравне со второй.

    Возможно, если бы была выбрана организация данных как в tensorflow (когда сначала идут
    пространственные размерности, и потом размерность каналов), то в текущих реализациях
    бы не было недостатка, связанного с порядками циклов.

------------
    Итого, лучшей по скорости работы является реализация с базовой сверткой (без оптимизации shared memory)
    и объединением свертки+активации -- стратегия 2